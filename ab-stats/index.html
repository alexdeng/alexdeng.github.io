<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>AB Statistics Presentation</title>

    <link href="bootstrap/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="reveal/css/reveal.css">
    <link rel="stylesheet" href="reveal/css/theme/white.css">
    <link rel="stylesheet" href="ab-stats.css">

    <script>
      var link = document.createElement( 'link' );
      link.rel = 'stylesheet';
      link.type = 'text/css';
      link.href = window.location.search.match( /print-pdf/gi ) ? 'reveal/css/print/pdf.css' : 'reveal/css/print/paper.css';
      document.getElementsByTagName( 'head' )[0].appendChild( link );
    </script>

  </head>
  <body>
    <div class="reveal">
      <div class="slides">
        <section id="title">
          <h1>Design <span class="title-divider">of</span> experiments</h1>
          <p>Statistical foundations for causal inference</p>
          <p>
            <small>
              Alex Deng <a href="http://alexdeng.github.io/ab-stats" target="_blank"> alexdeng.github.io/ab-stats </a>      
            </small>
          </p>
          <p>
            <small>  
            Forked from Lukas Vermeer's simulation based presentation  <br/>              
              <a href="http://twitter.com/lukasvermeer" target="_blank">@lukasvermeer</a> &mdash;  <a href="http://www.lukasvermeer.nl/ab-stats" target="_blank">lukasvermeer.nl/ab-stats</a>
            </small>
          </p>
        </section>

        <section data-markdown>
            <script type="text/template">
                    Correlation is not causation. 

                    A big part of AI as we know it mainly exploits correlation/joint distribution. 

                    Does causality really matter? 
            </script>
        </section>

        <section id="causal-inference">
          <h2>Making good decisions needs more than correlation</h2> 
          <p>
            <span class="fragment">Americans and English eat a lot of fat food. There is a high rate of cardiovascular diseases in US and UK.</span><br/>
            <span class="fragment">French eat a lot of fat food, but they have a low(er) rate of cardiovascular diseases.</span><br/>
            <span class="fragment">Americans and English drink a lot of alcohol. There is a high rate of cardiovascular diseases in US and UK.</span><br/>
            <span class="fragment">Italians drink a lot of alcohol but, again, they have a low(er) rate of cardiovascular diseases.</span>
          </p>
          <p>
            <span class="fragment">Conclusion? Eat and drink what you want. And you have a higher chance of getting a heart attack if you speak English! </span> <br/>
           </p>
        </section>

        <section> 
            <p>Drinking could help you live longer. According to a study, people who live to 90 or older often drink moderately.</p>
        </section>

        <section data-markdown>
            <script type="text/template">
                - Causality allows us to predict the impact of a change.
                    - Prediction of rain based on seeing umbrella is less useful than being able to <mark>forecast</mark> rain and weather <mark>modification</mark>.            
                - <!-- .element: class="fragment" --> Causality provides much more <mark>robust</mark> predictions than correlation. 
                    - Correlation can easily disappear or reverse direction easily by switching from one dataset to another. It can also lead to total reversal as in Simpson's paradox.
                    - A causal effect discovered from one population is more likely to still exist in another population. A drug works for American is more likely to be effective for French to some degree.
                <aside class="notes">
                    Heterogeneous treatment effect is more like secondary effect.
                </aside>
              </script>
        </section>

        <section id="app-rubin-full">
          <h3>Counterfactual framework <small>(Rubin Causal Model)</small></h3>
          <rubin-model display_ate></rubin-model>
        </section>

        <section id="fundamental-problem">
          <span class="text-muted">The fundamental problem of</span>
          <h2>causal inference</h2>
          <ol>
            <li class="fragment">Missing Data: We cannot expose units to both treatments <mark>simultaneously</mark>. We don't observe the <mark>counterfactual</mark></li>
            <li class="fragment">Noises: We don't directly observe <mark>underlying</mark> probabilities. Observations are noisy. </li>
            <li class="fragment">Sampling: We don't observe everyone. Only a sample. </li>
          </ol>
          <aside class="notes">
            - Other potential, but unquantifiable, sources of uncertainty also exist
              - The population may change
              - The treatment may change
              - The effect may change
            - Stability of these other factors is (often implicitly) assumed
          </aside>
        </section>

        <section id="app-rubin-fpci">
          <h3>What we can measure <small>(Rubin Causal Model)</small></h3>
          <rubin-model sample_name="Sample" randomize reveal_enabled></rubin-model>
          <span class="fragment" data-method="rerandomize"><small class="text-very-muted"><i class="glyphicon glyphicon-step-forward"></i></small></span>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
        </section>


        <section id="app-rubin-ate">
          <h3>What randomization gives us <small>(Rubin Causal Model)</small></h3>
          <rubin-model sample_name="Sample" randomize display_ate reveal_enabled></rubin-model>
          <span class="fragment" data-method="rerandomize"><small class="text-very-muted"><i class="glyphicon glyphicon-step-forward"></i></small></span>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
        </section>

        <section data-markdown id="explanation">
          <script type="text/template">
              - Each repeated experiment gives an estimated treatment effect
              - In each experiment, counterfactuals are missing
              - Randomization ensures they are missing completely at random, so partial data and full data follows the same distribution!
              - For each individual, the expectation of the yes cases will be the true underlying probability

              <p class="fragment">
                The average treatment effect can be <mark>IDENTIFIED</mark> through randomization in expectation.
              </p>              
          </script>

        </section>   

        <section id="app-expectation">
          <h3>Repeating the same experiment <small>(Expectation)</small></h3>
          <simulation v-bind:effect="0.1" display_true_effect display_observed_effect reveal_enabled></simulation>
          <span class="fragment" data-method="step"><small class="text-very-muted"><i class="glyphicon glyphicon-step-forward"></i></small></span>
          <span class="fragment" data-method="step"><small class="text-very-muted"><i class="glyphicon glyphicon-step-forward"></i></small></span>
          <span class="fragment" data-method="step"><small class="text-very-muted"><i class="glyphicon glyphicon-step-forward"></i></small></span>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
        </section>

        <section data-markdown id="noises">
          <script type="text/template">
              Randomzation gives us an identification strategy for the causal effect only in a form of expectation. 
              
              Our estimate for the treatment effect is still random due to other source of randomness.             

              In reality we don't get to repeat the experiment so many times as we did in simulations. If we only observe one treatment effect estimate, what can we say about its unknown expectation?

              <!-- .element: class="fragment" -->In other words, we need <mark>Statistical Inference</mark> 
          </script>
        </section>  
     
     <!--    <section id="randomization">
          <span class="text-muted">Randomization ensures only three things can</span>
          <h2>explain a difference</h2>

          <ol>
            <li class="fragment"><mark>Causation</mark> resulted in people behaving differently when treatment was applied</li>
            <li class="fragment"><mark>Pure chance</mark> resulted in a difference between the two groups unrelated to the treatment</li>
            <li class="fragment"><mark>Measurement error</mark> resulted in an unintended difference in results unrelated to user behaviour</li>
          </ol>
          <p class="fragment">Statistical methods help separate causation from noises</p>
        </section> -->

        <section id="null-hypothesis">
          <span class="text-muted">We want to reject the</span>
          <h2>null hypothesis</h2>
          <p>
            <span class="fragment">The <mark>null hypothesis</mark> assumes average treatment effect is zero; any difference we observe is simply due to chance.</span>
          </p>
          <p>
            <span class="fragment">If we could reasonably rule out chance, we might reject the null and consider this to be evidence for the <mark>alternative hypothesis</mark>.</span>
          </p>

          <aside class="notes">
            - We will want to refute the hypothesis that there is no effect
              - We will consider rejection of the “null hypothesis” as evidence for the “alternative hypothesis”
          </aside>
        </section>

        <section id="p-value">
          <span class="text-muted">We compute a</span>
          <h2>p-value</h2>
          <p>
            <span class="fragment">We assume the null hypothesis is true and compute the p-value.</span>
          </p>
          <p>
            <span class="fragment">Assuming there is no effect, the p-value is the probability of seeing a particular result or more extreme by chance.</span>
          </p>
          <p>
            <span class="fragment"><b>How likely is this (or more extreme) result <mark>assuming the null is true</mark>?</b></span>
            <span class="fragment"><b>Reject null if p-value is below a threshold.</b></span>
          </p>
        </section>

<!--         <section id="loaded-die">
          <span class="text-muted">Is this die</span>
          <h2>Fair?</h2>
          <p class="dice"><span class="fragment six">&#x2685</span><span class="fragment six">&#x2685</span><span class="fragment six">&#x2685</span></p>
          <p>
            <span class="fragment">p = 0.00462962</span>
            </br>
            <span class="fragment text-muted"><small>(Not fair; I cheated)</small></span>
          </p>

          <aside class="notes">
            - We might argue that small odds support accepting an alternative explanation
              - For instance that the die is loaded, of that I can influence the result through telepathy
          </aside>
        </section> -->

<!--         <section id="significance-threshold">
          <span class="text-muted">We need to pick a</span>
          <h2>threshold</h2>
          <p>
            <span class="fragment">One swallow does not make a summer, nor one fine day,</span>
            <span class="fragment">but how many swallows do we count before we pack away our umbrellas?</span>
          </p>
          <p>
            <span class="fragment"><b>Scientific standard for significance:</b> <mark>p < 0.05</mark></span>
          </p>

          <aside class="notes">
            - Sometimes we will get “unlucky” in our randomization
              - We will have to decide at which point we will reject the idea that our result could be chance
              - At this point, we will accept the alternative hypothesis and argue there is a causal effect
          </aside>
        </section> -->

<!--         
        <section id="misinterpreted-p-value">
          <span class="text-muted">p-values are often<small>[2]</small></span>
          <h2>misinterpreted</h2>

          <span class="fragment">Some examples of <mark>incorrect</mark> interpretations</span>
          <ol>
            <li class="fragment">p = .05 means the null hypothesis has only a 5% chance of being true</li>
            <li class="fragment">A non-significant difference (e.g. p > .05) means there is no difference between groups</li>
            <li class="fragment">p = .05 means that we have observed data that would occur only 5% of the time under the null</li>
            <li class="fragment">p = .05 means that if you reject the null, the probability of a type I error (false positive) is 5%</li>
          </ol>

          <p><small>[2] Goodman, Steve 2008. “A dirty dozen: twelve P-value misconceptions.” Seminars in Hematology, 45 (2008), pp. 135-140.</small></p>

          <aside class="notes">
            - p-value gives us Prob(X >= x | H0), whereas what we want is Prob(H0 | X = x)
            - Here are some incorrect statements from Steve Goodman’s A Dirty Dozen[2]
          </aside>
        </section>
         -->

        <section id="errors">
          <span class="text-muted">Two types of</span>
          <h2>errors</h2>

          <ol>
            <li class="fragment"><mark>Type-I (False Positive)</mark> is the incorrect rejection of a true null hypothesis; <span class="fragment">we cried wolf when there was none</span></li>
            <li class="fragment"><mark>Type-II (False Negative)</mark> is the failure to reject a false null hypothesis; <span class="fragment">we failed to detect a real effect</span></li>
          </ol>
          <p class = "fragment"> p-value is the Type-I error <b>assuming the null is true</b>;  <span class="fragment">the threshold we set for p-value controls Type-I error</span></p>

          <aside class="notes">
            - The result might simply not be that unlikely when assuming the null is true
          </aside>
        </section>

        <section id="app-type-i">
          <h3>Repeating the same experiment <small>(No effect)</small></h3>
          <simulation v-bind:effect="0.0" display_true_effect display_type_i reveal_enabled></simulation>
          <span class="fragment" data-method="step"><small class="text-very-muted"><i class="glyphicon glyphicon-step-forward"></i></small></span>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
          <aside class="notes">
              - We select threshold to make it so
            </aside>
        </section>

        <section id="app-type-ii">
          <h3>Repeating the same experiment <small>(Small effect)</small></h3>
          <simulation v-bind:effect="0.05" display_true_effect display_type_ii reveal_enabled></simulation>
          <span class="fragment" data-method="step"><small class="text-very-muted"><i class="glyphicon glyphicon-step-forward"></i></small></span>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
        </section>

        <section id="power">
          <span class="text-muted">The importance of</span>
          <h2>Statistical power</h2>

          <p>
            <span class="fragment">Statistical power is the probability that the test <mark>correctly rejects</mark> the null hypothesis when the alternative hypothesis is true. <br/>(1 - Type-II error rate)</span>
          </p>
          <p>
            <span class="fragment"><b>Two main things affect statistical power:</b></span>
            <ul>
              <li class="fragment">Sample size <span class="text-muted">(more is better)</span></li>
              <li class="fragment">Effect size <span class="text-muted">(more is better)</span></li>
            </ul>
          </p>

          <aside class="notes">
            - Effect size is unknown but assumed fixed
            - Sample size may be increased is low power is expected
          </aside>
        </section>

        <section id="app-type-ii-2">
          <h3>Repeating the same experiment <small>(More power)</small></h3>
          <simulation v-bind:effect="0.05" v-bind:n="2000" display_type_ii display_power reveal_enabled></simulation>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
        </section>

<!--         <section id="app-type-ii-3">
          <h3>Repeating the same experiment <small>(More power!!)</small></h3>
          <simulation v-bind:effect="0.05" v-bind:n="4000" display_type_ii display_power reveal_enabled></simulation>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
        </section> -->
        <section id="app-type-ii-4">
            <h3>Repeating the same experiment <small>(More power from larger effect)</small></h3>
            <simulation v-bind:effect="0.1" v-bind:n="1000" display_type_ii display_power reveal_enabled></simulation>
            <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
          </section>

          <section id="errors-mands">
              <span class="text-muted">Another Two types of</span>
              <h2>errors</h2>
    
              <ol>
                <li class="fragment"><mark>Type-M (Magnitude)</mark> is the expected ratio between the estimated effect to the true effect given rejection of the null</li>
                <li class="fragment"><mark>Type-S (Sign)</mark> is the probability that our estimate is of different sign than the true effect given rejection of the null </li>
              </ol>
            </section>
        <section id="app-type-m">
            <h3>Type-S and Type-M: moderate power</h3>
            <simulation v-bind:effect="0.05" display_true_effect display_type_ii display_type_s display_type_m display_power reveal_enabled></simulation>
            <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
          </section>
          <section id="app-type-s">
            <h3>Type-S and Type-M: very low power</h3>
            <simulation v-bind:effect="0.01" display_true_effect display_type_ii display_type_s display_type_m display_power reveal_enabled></simulation>
            <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
          </section>

          <section id="app-type-m2">
            <h3>Type-S and Type-M: high power</h3>
            <simulation v-bind:effect="0.075" display_true_effect display_type_ii display_type_s display_type_m display_power reveal_enabled></simulation>
            <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
          </section>

          <section id="app-type-m3">
            <h3>Type-S and Type-M: very high power</h3>
            <simulation v-bind:effect="0.1" display_true_effect display_type_ii display_type_s display_type_m display_power reveal_enabled></simulation>
            <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
          </section>
          <section id="power2">
            <span class="text-muted">The importance of</span>
            <h2>Statistical power, AGAIN</h2>
  
            <p>
              <p class="fragment">Type-M error always exist in NHST framework. Estimates is more likely to overestimate the true effect.</p> 
              <p class="fragment">Type-M error could still be high for moderate power like 50%. Although still a fair chance to reject the null, the estimated effects are on average exaggerated by 50%. (Winner's Curse)</p>
              <p class="fragment">Type-M error is less severe for power above 80% </p>
              <p class="fragment">Fortunately, Type-S error is very rare </p>
            </p>
            <p><small class="fragment">Jiannan Lu, Yixuan Qiu, Alex Deng 2018 "A note on type S/M errors in hypothesis testing"</small></p>
            </section>
        <section id="protocol">
          <span class="text-muted">About Peeking and multiple testing</span>

          <p>
            <span class="fragment">The methods described assume the PROTOCOL of testing one hypothesis with one analysis using one set of data;</span>
            <span class="fragment">violations of protocol such as <mark>peeking</mark> and <mark>multiple testing</mark> increase the type-I error rate</span>
          </p>
        </section>

<!--         <section id="app-dice">
          <span class="text-muted">Can telekenisis influence</span>
          <h2>Three dice?</h2>
          <span class="fragment"><dice reveal_enabled></dice></span>
          <span class="fragment" data-method="rerandomize"></span>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden></span>
          <p>
            <span class="fragment">p = 1</span>
            </br>
            <span class="fragment text-muted"><small>(Fair die; I still cheated)</small></span>
          </p>
        </section>
 -->
        <section id="app-multiple-testing">
          <h3>Peeking twice</h3>
          <simulation v-bind:effect="0.00" v-bind:peek="2" display_true_effect display_type_i reveal_enabled></simulation>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
        </section>

        <section id="app-multiple-testing-2">
          <h3>Peeking 100x</h3>
          <simulation v-bind:effect="0.00" v-bind:peek="100" display_true_effect display_type_i reveal_enabled></simulation>
          <span class="fragment" data-method="toggle_repeat" trigger-hidden><small class="text-very-muted"><i class="glyphicon glyphicon-forward"></i></small></span>
        </section>

        <section id="adaptive-methods">
          <span class="text-muted">Reasons for violating</span>
          <h2>Protocol</h2>

          <p>
            <span class="fragment">More flexible protocols may be desirable</span>
            <ul>
              <li class="fragment"><mark>early stopping rules</mark> to mitigate damage</li>
              <li class="fragment"><mark>early shipping</mark> to minimize opportunity cost</li>
              <li class="fragment"><mark>multiple variants</mark> to test several alternatives</li>
              <li class="fragment"><mark>multiple metrics</mark> to guard business KPIs</li>
            </ul>
          </p>
          <div class="fragment">
            <p>All these require protocol adjustments</p>
          </div>
        </section>

        <section id="references">
          <h2>References</h2>

          <ol>
            <li><small>Rubin, Donald B. 1974. “Estimating Causal Effects of Treatments in Randomized and Nonrandomized Studies.” Journal of Educational Psychology 66 (5): 688–701. (<a href="http://dx.doi.org/10.1037/h0037350" target="_blank">link</a>)</small></li>
            <li><small>Goodman, Steve 2008. “A dirty dozen: twelve P-value misconceptions.” Seminars in Hematology, 45 (2008), pp. 135-140. (<a href="https://www.researchgate.net/publication/5272766_A_Dirty_Dozen_Twelve_P-Value_Misconceptions" target="_blank">link</a>)</small></li>
            <li><small>Kohavi, R., Longbotham, R., Sommerfield, D. et al. 2009 “Controlled experiments on the web: survey and practical guide” Data Min Knowl Disc (2009) 18: 140. (<a href="http://bit.ly/expSurvey" target="_blank">link</a>)</small></li>
            <li><small>Alex Deng, Tianxi Li, Yu Guo 2014 “Statistical Inference in Two-Stage Online Controlled Experiments with Treatment Selection and Validation” WWW '14. 609–618.(<a href="http://www.exp-platform.com/Documents/p609-deng.pdf" target="_blank">link</a>)</small></li>
            <li><small>Jiannan Lu, Yixuan Qiu, Alex Deng 2018 "A note on type S/M errors in hypothesis testing"(<a href="https://psyarxiv.com/n53zs/download" target="_blank">link</a>)</small></li>
            <li><small>Alex Deng, Jiannan Lu, Shouyuan Chen 2016 "Continuous monitoring of A/B tests without pain: Optional stopping in Bayesian testing"(<a href="https://arxiv.org/pdf/1602.05549" target="_blank">link</a>)</small></li>
          </ol>
        </section>
      </div>
    </div>

    <script type="text/javascript" src="d3/d3.js"></script>
    <script type="text/javascript" src="vue/vue.min.js"></script>
    <script type="text/javascript" src="vue-components.js"></script>
    <script type="text/javascript" src="reveal/lib/js/head.min.js"></script>
    <script type="text/javascript" src="reveal/js/reveal.js"></script>
    <script type="text/javascript">
      Reveal.initialize({
        controls: false,
        progress: true,
        history: true,
        center: true,
        width: 1140,
        height: 960,
        margin: 0.05,
        slideNumber: 'c/t',
        transition: 'slide',
        dependencies: [
        { src: 'reveal/lib/js/classList.js', condition: function() { return !document.body.classList; } },

        // Interpret Markdown in <section> elements
        { src: 'reveal/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
        { src: 'reveal/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },

        { src: 'reveal/plugin/notes/notes.js', async: true }
        ]
      });

      const EventBus = new Vue();

      new Vue({ el: '#app-rubin-full' });
      new Vue({ el: '#app-rubin-fpci' });
      new Vue({ el: '#app-rubin-ate' });

      new Vue({ el: '#app-expectation' });
      //new Vue({ el: '#app-one-trial' });
      //new Vue({ el: '#app-one-trial-2' });
      new Vue({ el: '#app-type-i' });
      new Vue({ el: '#app-type-ii' });
      new Vue({ el: '#app-type-ii-2' });
      //new Vue({ el: '#app-type-ii-3' });
      new Vue({ el: '#app-type-ii-4' });
      new Vue({ el: '#app-type-m'});
      new Vue({ el: '#app-type-m2'});
      new Vue({ el: '#app-type-m3'});
      new Vue({ el: '#app-type-s'});
      new Vue({ el: '#app-multiple-testing' });
      new Vue({ el: '#app-multiple-testing-2' });
      //new Vue({ el: '#app-dice' });

      Reveal.addEventListener( 'fragmentshown', function( event ) {
        if (event.fragment.hasAttribute('data-method')) {
          EventBus.$emit('fragmentMethod', { id: event.fragment.parentNode.id, method: event.fragment.getAttribute('data-method')});
        }
      } );
      Reveal.addEventListener( 'fragmenthidden', function( event ) {
        if (event.fragment.hasAttribute('data-method') && event.fragment.hasAttribute('trigger-hidden')) {
          EventBus.$emit('fragmentMethod', { id: event.fragment.parentNode.id, method: event.fragment.getAttribute('data-method')});
        }
      } );

      if (window.location.search.match( /print-pdf/gi )) {
        EventBus.$emit('fragmentMethod', { id: 'app-expectation', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-type-i', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-type-ii', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-type-ii-2', method: 'toggle_repeat'});
        //EventBus.$emit('fragmentMethod', { id: 'app-type-ii-3', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-type-ii-4', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-type-m', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-type-s', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-type-m2', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-type-m3', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-multiple-testing', method: 'toggle_repeat'});
        EventBus.$emit('fragmentMethod', { id: 'app-multiple-testing-2', method: 'toggle_repeat'});
        //EventBus.$emit('fragmentMethod', { id: 'app-dice', method: 'toggle_repeat'});
      }
    </script>
  </body>
</html>
